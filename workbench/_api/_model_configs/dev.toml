remote = false

[models]

[models.one]
name = "openai-community/gpt2"
chat = false

[models.one.rename]
transformer = "model"
h = "layers"
c_proj = "o_proj"

[models.one.config]
n_heads = 12
n_layers = 12

# # [models.two]
# # name = "Qwen/Qwen3-0.6B-Base"
# # chat = false

# # [models.two.rename]
# # embed_out = "lm_head"
# # norm = "ln_f"

# # [models.two.config]
# # n_heads = 16
# # n_layers = 28

# [models.two]
# name = "EleutherAI/gpt-j-6b"
# chat = false

# [models.two.rename]
# transformer = "model"
# h = "layers"
# out_proj = "o_proj"

# [models.two.config]
# n_heads = 16
# n_layers = 28

# [models.three]
# name = "meta-llama/Llama-3.1-8B"
# chat = false

# [models.three.rename]
# norm = "ln_f"
# self_attn = "attn"

# [models.three.config]
# n_heads = 32
# n_layers = 32

# [models.four]
# name = "meta-llama/Llama-3.1-70B"
# chat = false

# [models.four.rename]
# norm = "ln_f"
# self_attn = "attn"

# [models.four.config]
# n_heads = 64
# n_layers = 80

# [models.five]
# name = "meta-llama/Llama-3.2-1B-Instruct"
# chat = true

# [models.five.rename]
# norm = "ln_f"
# self_attn = "attn"

# [models.five.config]
# n_heads = 32
# n_layers = 16

# [models.six]
# name = "meta-llama/Llama-3.3-70B-Instruct"
# chat = true

# [models.six.rename]
# norm = "ln_f"
# self_attn = "attn"

# [models.six.config]
# n_heads = 64
# n_layers = 80


# [models.seven]
# name = "meta-llama/Llama-3.1-405B-Instruct"
# chat = true

# [models.seven.rename]
# norm = "ln_f"
# self_attn = "attn"

# [models.seven.config]
# n_heads = 128
# n_layers = 126

# [models.eight]
# name = "meta-llama/Meta-Llama-3.1-405B"
# chat = false

# [models.eight.rename]
# norm = "ln_f"
# self_attn = "attn"

# [models.eight.config]
# n_heads = 128
# n_layers = 126
