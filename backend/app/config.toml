[models]

[models.one]
name = "EleutherAI/gpt-j-6b"
serve = true
chat = false

[models.one.rename]
transformer = "model"
h = "layers"

[models.two]
name = "meta-llama/Meta-Llama-3.1-8B"
serve = true
chat = false

[models.two.rename]
norm = "ln_f"

# [models.three]
# name = "meta-llama/Meta-Llama-3.1-8B-Instruct"
# serve = false
# chat = true

# [models.three.rename]
# norm = "ln_f"

# [models.four]
# name = "meta-llama/Meta-Llama-3.1-70B"
# serve = true
# chat = false

# [models.four.rename]
# norm = "ln_f"

# [models.five]
# name = "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
# serve = true
# chat = false

# [models.five.rename]
# norm = "ln_f"

# [models.six]
# name = "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
# serve = true
# chat = false

# [models.six.rename]
# norm = "ln_f"