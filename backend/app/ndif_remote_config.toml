# STANDARD NAMING:
# model.layers.i.attn
# model.layers.i.mlp
# model.ln_f
# model.lm_head

remote = true
next_public_base_url = "https://interp-workbench.vercel.app"
callback_url = "/api/status-update"

[models]

[models.one]
name = "EleutherAI/gpt-j-6b"
chat = false

[models.one.rename]
transformer = "model"
h = "layers"

[models.two]
name = "meta-llama/Meta-Llama-3.1-8B"
chat = false

[models.two.rename]
norm = "ln_f"
self_attn = "attn"

[models.three]
name = "meta-llama/Meta-Llama-3.1-70B"
chat = false

[models.three.rename]
norm = "ln_f"
self_attn = "attn"

# [models.four]
# name = "meta-llama/Meta-Llama-3.1-8B-Instruct"
# chat = true

# [models.four.rename]
# norm = "ln_f"

# [models.five]
# name = "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
# chat = false

# [models.five.rename]
# norm = "ln_f"

# [models.six]
# name = "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
# chat = false

# [models.six.rename]
# norm = "ln_f"